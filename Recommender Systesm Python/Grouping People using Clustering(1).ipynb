{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import feedparser\n",
    "import re\n",
    "from PIL import Image,ImageDraw\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Signal v. Noise\n",
      "2 Eschaton\n",
      "2 John Battelle's Search Blog\n",
      "2 Guy Kawasaki\n",
      "2 Google Blogoscoped\n",
      "2 RSS feed â€“ Search Engine Watch\n",
      "2 0\n",
      "2 0\n",
      "2 Gigaom\n",
      "2 Gizmodo\n",
      "2 0\n",
      "2 The Official Google Blog\n",
      "2 Google Operating System\n",
      "2 Creating Passionate Users\n",
      "2 Instapundit\n",
      "3 Jeremy Zawodny's blog\n",
      "2 Joi Ito's Web\n",
      "2 Mashable\n",
      "2 0\n",
      "2 0\n",
      "2 NB Blog Feed\n",
      "2 PaulStamatiou.com - Technology, Design and Photography\n",
      "2 Power LinePower Line\n",
      "2 O'Reilly Radar\n",
      "2 pharyngula\n",
      "2 0\n",
      "2 Seth Godin's Blog on marketing, tribes and respect\n",
      "2 Slashdot\n",
      "2 ThinkProgress\n",
      "2 The Dish\n",
      "2 WIL WHEATON dot NET\n",
      "2 0\n",
      "2 456 Berea Street\n",
      "2 Autoblog\n",
      "2 The Write News\n",
      "2 blog maverick\n",
      "2 Boing Boing\n",
      "2 BuzzMachine\n",
      "2 Captain's Quarters\n",
      "2 COOL HUNTING\n",
      "2 Copyblogger\n",
      "2 Latest from Crooks and Liars\n",
      "2 0\n",
      "2 Deadspin\n",
      "2 Tech\n",
      "2 Engadget RSS Feed\n",
      "2 Gapingvoid\n",
      "2 Gothamist\n",
      "2 0\n",
      "2 0\n",
      "2 Joel on Software\n",
      "2 Kotaku\n",
      "2 kottke.org\n",
      "2 Lifehack - Feed\n",
      "2 Lifehacker\n",
      "2 0\n",
      "2 Make: DIY Projects and Ideas for Makers\n",
      "2 Matt Cutts: Gadgets, Google, and SEO\n",
      "2 0\n",
      "2 mezzoblue\n",
      "2 Neil Gaiman's Journal\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 Derek Powazek\n",
      "2 ProBlogger\n",
      "2 Quick Online Tips\n",
      "2 ReadWrite\n",
      "2 Schneier on Security\n",
      "2 ScienceBlogs - Where the world discusses science\n",
      "2 Search Engine Roundtable\n",
      "2 ShoeMoney\n",
      "2 Sifry's Alerts - David Sifry\n",
      "2 SimpleBits\n",
      "2 0\n",
      "2 Steve Pavlina\n",
      "2 Talking Points Memo\n",
      "2 ongoing by Tim Bray\n",
      "2 TechCrunch\n",
      "2 Techdirt.\n",
      "2 0\n",
      "2 0\n",
      "2 TMZ.com\n",
      "2 Latest Items from TreeHugger\n",
      "2 0\n",
      "2 We Make Money Not Art\n",
      "2 Wired\n",
      "2 Wonkette\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "class preproccess:\n",
    "    '''this will read the links from file'''\n",
    "    def readlinksfromfile(self,address):\n",
    "        lines=open(address,'r')\n",
    "        links=lines.read().split('\\n')\n",
    "        return links\n",
    "    def readdata(self,mylist):\n",
    "        wordcount={}\n",
    "        apcount={}\n",
    "        count=0\n",
    "        for feedurl in mylist:\n",
    "            title,wc=self.getwordcounts(feedurl)\n",
    "            print(count,title)\n",
    "            if title==0:\n",
    "                continue\n",
    "            wordcount[title]=wc\n",
    "            for word,count in wc.items():\n",
    "                apcount.setdefault(word,0)\n",
    "                if count>1:\n",
    "                    apcount[word]+=1\n",
    "            count=count+1\n",
    "         \n",
    "        return apcount,wordcount\n",
    "    \n",
    "    ''' Return ttitle and dictionary of word count for an RSS feed'''        \n",
    "    def getwordcounts(self,feedurl):\n",
    "        \n",
    "        #Parse the feed\n",
    "        d=feedparser.parse(feedurl)\n",
    "        wc={}\n",
    "        if d.entries==[]:\n",
    "            return 0,0\n",
    "        for e in d.entries:\n",
    "            if 'summary' in e:\n",
    "                summary=e.summary\n",
    "            else:\n",
    "                summary=e.description\n",
    "            #Extract a list of Words\n",
    "            words=self.getwords(e.title+' '+summary)\n",
    "            for word in words:\n",
    "                wc.setdefault(word,0)\n",
    "                wc[word]+=1\n",
    "        return d.feed.title,wc\n",
    "    '''It removes the tags fo html from txt'''\n",
    "    def getwords(self,html):\n",
    "        #Remove all the HTML tags\n",
    "        txt=re.compile(r'<[^>]+>').sub('',html)\n",
    "        #Split word by all Non-alpha charectors\n",
    "        words=re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "        #Convert to lowercase\n",
    "        return [word.lower() for word in words if word!='']\n",
    "\n",
    "    \n",
    "    # 10 percent as the lower bound and 50 percent as the upper bound,\n",
    "    def savingintofile(self,apcount,wordcount,length):\n",
    "        wordlist=[]\n",
    "        for w,bc in apcount.items():\n",
    "            frac=float(bc)/length\n",
    "            if frac>0.1 and frac<0.5:\n",
    "                wordlist.append(w)\n",
    "\n",
    "        out=open('blogdataset2','w+',encoding='utf-8')\n",
    "        out.write(\"Blog\")\n",
    "        for word in wordlist:\n",
    "            out.write('\\%s'%word)\n",
    "        out.write(\"\\n\")    \n",
    "        #write frequancy under the label\n",
    "        for blogname,wc in wordcount.items():\n",
    "            out.write(blogname)\n",
    "            for word in wordlist:\n",
    "                if word in wc:\n",
    "                    out.write('\\t%d'%wc[word])\n",
    "                else:\n",
    "                    out.write(\"\\t0\")\n",
    "            out.write(\"\\n\")\n",
    "\n",
    "        \n",
    "            \n",
    "# obj=preproccess()\n",
    "# links=obj.readlinksfromfile('feedlist.txt')\n",
    "# apcount,wordcount=obj.readdata(links)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
